# -*- coding: utf-8 -*-
"""ListenerSpeaker_TF_LAS.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NtvihQ8HpTvSSwd7mRrghPe4bATSWprQ

### Connect to Local Runtime
jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0

### CUDA Update:
https://www.tensorflow.org/install/gpu#software_requirements

##### $$ Update CUDNN
https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#installwindows
"""

# Commented out IPython magic to ensure Python compatibility.
# Install TensorFlow
# !pip install -q tensorflow-gpu==2.0.0-beta1

try:
#   %tensorflow_version 2.x  # Colab only.
except Exception:
  pass

import tensorflow as tf
import tensorflow_probability as tfp
from tensorflow import keras
from tensorflow.keras import layers
print(tf.__version__)
print(tfp.__version__)

gpu_available = tf.test.is_gpu_available()
is_cuda_gpu_available = tf.test.is_gpu_available(cuda_only=True)
is_cuda_gpu_min_3 = tf.test.is_gpu_available(True, (3,0))

# Uncomment to see where your variables get placed (see below)
tf.debugging.set_log_device_placement(False)

## Collab Pro
def monitor_gpu():
  gpu_info = !nvidia-smi
  gpu_info = '\n'.join(gpu_info)
  if gpu_info.find('failed') >= 0:
    print('Select the Runtime > "Change runtime type" menu to enable a GPU accelerator, ')
    print('and then re-execute this cell.')
  else:
    print(gpu_info)
monitor_gpu()

## RAM
from psutil import virtual_memory
ram_gb = virtual_memory().total / 1e9
print('Your runtime has {:.1f} gigabytes of available RAM\n'.format(ram_gb))

if ram_gb < 20:
  print('To enable a high-RAM runtime, select the Runtime > "Change runtime type"')
  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')
  print('re-execute this cell.')
else:
  print('You are using a high-RAM runtime!')

print(tf.test.is_gpu_available())
print(tf.config.list_physical_devices('CPU'))
print(tf.config.list_physical_devices('GPU'))
print(tf.config.list_physical_devices('TPU'))

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sys, os, time
import tensorflow.keras.layers as L
from tensorflow.keras import Model

# Evaluation
import Levenshtein as LEV

# Kaggle DataSet
# ! pip install -q kaggle
!pip install --upgrade --force-reinstall --no-deps kaggle # force install of latest version
from google.colab import files
files.upload() # uncomment if no kaggle.json present in colab
# Make directory named kaggle and copy kaggle.json file there.
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/
# Change Permisson
! chmod 600 ~/.kaggle/kaggle.json
# # Check if everying is working
# ! kaggle datasets list
# # Downloading competetion data
# !kaggle competitions download -c gan-getting-started
# !ls
# from kaggle_datasets import KaggleDatasets

# ! kaggle datasets list
# Downloading data from Kaggle competition
## Skippable if using LOCAL ENV
! kaggle competitions download -c 11785-hw4-fall2018

!unzip 11785-hw4-fall2018.zip -d hw4_data

"""## Data Loading"""

LETTER_LIST = ['<pad>', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', \
               'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '-', "'", '.', '_', '+', ' ','<sos>','<eos>']


'''
Optional, create dictionaries for letter2index and index2letter transformations
    '<sos>': 33
    '<eos>': 34
'''
def create_dictionaries(letter_list):
    n = len(letter_list)
    letter2index = {letter_list[i]:i for i in range(0, n)}
    index2letter = {i:letter_list[i] for i in range(0, n)}
    return letter2index, index2letter

letter2index, index2letter = create_dictionaries(LETTER_LIST)

'''
Loading all the numpy files containing the utterance information and text information
- Input: training utterances each of variable duration and 40 frequency bands (L, F=40)
- Target: the transcripts corresponding to the utterances in train/dev; Shape: (B, )
'''
def load_data(dataPath):
    speech_train = np.load(dataPath+"train.npy", allow_pickle=True, encoding='bytes')
    speech_dev = np.load(dataPath+"dev.npy", allow_pickle=True, encoding='bytes')
    speech_test = np.load(dataPath+"test.npy", allow_pickle=True, encoding='bytes')

    transcript_train = np.load(dataPath+"train_transcripts.npy", allow_pickle=True, encoding='bytes')
    transcript_dev = np.load(dataPath+"dev_transcripts.npy", allow_pickle=True, encoding='bytes')

    return speech_train, speech_dev, speech_test, transcript_train, transcript_dev

'''
Transforms alphabetical input to numerical input, replace each letter by its corresponding
index from letter_list
  '<sos>': 33
  '<eos>': 34
'''
def transform_letter_to_index(transcript):
    '''
    :param transcript :(N, ) Transcripts are the text input
    :- letter2index: Letter list defined above, map letter to index from LETTER_LIST
    :return letter_to_index_list: Returns a list for all the transcript sentence to index
    '''
    letter_to_index_list = []
    for sent in transcript:
        letters = [letter2index['<sos>']] # start of sequence
        for word in sent:
            # Converte from byte format to string for mapping
            s = word.decode('utf-8')
            for c in s:
                letters.append(letter2index[c])
            # Space between each word
            letters.append(letter2index[' '])
        # pop the ending space, and replace with '<eos>'
        letters.pop()
        letters.append(letter2index['<eos>'])
        letter_to_index_list.append(letters)
    return letter_to_index_list


def transform_index_to_letter(index, stopIdxs, igonre_idxs=[]):
    index_to_letter_list = []
    for r in index:
        curr = ""
        for i in r:
            # Reached the end of the sentence
            if i in stopIdxs:
                break
            elif i in igonre_idxs:
                continue
            else:
                curr += index2letter[i]
        index_to_letter_list.append(curr)
    return index_to_letter_list

data_path = 'hw4_data/'
speech_train, speech_dev, speech_test, transcript_train, transcript_dev = load_data(data_path)

## Debug
print(type(speech_train))
print(type(speech_train[0]))
print(speech_train.shape)
print(speech_train[0].shape)
print(speech_train[0])
print(transcript_train.shape)
print(transcript_train[0])

for word in transcript_train[0]:
  # convert from byte format to string
  print('Byte Word: {}, Converted Word: {}'.format(word, word.decode('utf-8')))

# Preprocess transcript to char level index
character_text_train = transform_letter_to_index(transcript_train)
character_text_dev = transform_letter_to_index(transcript_dev)

## Test Data

## Debug
print(transcript_train.shape)
print(transcript_train[0])
print(len(character_text_train))
print(character_text_train[0])

print("Raw script: \n", transcript_dev[0])
print("Indexed and '<sos>+<eos>' script: \n", character_text_dev[0])
print("Recovered script: \n", transform_index_to_letter(character_text_dev, [])[0])
print("Recovered script with no special character(s): \n", transform_index_to_letter(character_text_dev, [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])[0])

## Load Dataset from Generator
def gen_dev():
  for utter, trans in zip(speech_dev, character_text_dev):
    # print(utter.shape) # comment during use...
    utter.astype(np.float32)
    
    utter_len = len(utter)
    trans_len = len(trans)
    # print(utter, trans, utter_len, trans_len)
    yield utter, trans, utter_len, trans_len

def gen_train():
  for utter, trans in zip(speech_train, character_text_train):
    # print(utter.shape) # comment during use...
    utter.astype(np.float32)
    
    utter_len = len(utter)
    trans_len = len(trans)
    # print(utter, trans, utter_len, trans_len)
    yield utter, trans, utter_len, trans_len

def gen_test():
  for utter in speech_test:
    # print(utter.shape) # comment during use...
    utter.astype(np.float32)
    
    trans = [0]
    utter_len = len(utter)
    # trans_len = len(trans)
    # print(utter, trans, utter_len, trans_len)
    yield utter, trans, utter_len, 1

# Create dataset from generator
# The output shape is variable: (None,)
# dataset = tf.data.Dataset.from_generator(gen, tf.int64, tf.TensorShape([None]))

# '''args have to be Tensor...'''
ds = tf.data.Dataset.from_generator(gen_dev, output_types=(tf.float32, tf.int32, tf.int32, tf.int32), output_shapes=(tf.TensorShape([None, 40]), tf.TensorShape([None]), (), ())) #tf.data.Dataset.from_generator(gen, args=[], output_types=tf.float32, output_shapes = (), )

ds_train = tf.data.Dataset.from_generator(gen_train, output_types=(tf.float32, tf.int32, tf.int32, tf.int32), output_shapes=(tf.TensorShape([None, 40]), tf.TensorShape([None]), (), ()))

ds_test = tf.data.Dataset.from_generator(gen_test, output_types=(tf.float32, tf.int32, tf.int32, tf.int32), output_shapes=(tf.TensorShape([None, 40]), tf.TensorShape([None]), (), ()))

print(len(list(ds.as_numpy_iterator())))
for batch in ds.take(2):
  print(type(batch))
  print(batch[0].shape)
  print(batch[0].numpy())
  print(batch[1].shape)
  print(batch[1].numpy())
  print(batch[2])
  print(batch[3])
  print("=====================")

print(len(list(ds_test.as_numpy_iterator())))

for batch in ds_test.take(1):
  print(type(batch))
  print(batch[0].shape)
  print(batch[0].numpy())
  print(batch[1].shape)
  print(batch[1].numpy())
  print(batch[2])
  print(batch[3])
  print("=====================")

"""### PreProcessing"""

## Pre-Processing

### shuffle
ds_shuffle = ds.shuffle(1024)

ds_train_shuffle = ds_train.shuffle(25000)

print(len(list(ds_shuffle.as_numpy_iterator())))
for batch in ds_shuffle.take(2):
  print(type(batch))
  print(batch[0].shape)
  print(batch[0].numpy())
  print(batch[1].shape)
  print(batch[1].numpy())
  print(batch[2])
  print(batch[3])
  print("=====================")

# lib padded batching
# Batching tensors with padding
batched_ds = ds.padded_batch(32)

batched_ds_train = ds_train_shuffle.padded_batch(32) # OOM DEBUG # BATCH_SIZE = 64

batched_ds_test = ds_test.batch(1)

print(len(list(batched_ds.as_numpy_iterator())))
### Generator Padded inputs
for batch in batched_ds.take(1):
  print(type(batch))
  print(type(batch[0]))
  print(batch[0].shape)
  print(batch[0][0].numpy()) # first utterance (T, C/F=40)
  print(batch[2].shape)
  print(batch[2].numpy())


for batch in batched_ds_train.take(1):
  print(type(batch))
  print(type(batch[0]))
  print(batch[0].shape)
  print(batch[0][0].numpy()) # first utterance (T, C/F=40)
  print(batch[2].shape)
  print(batch[2].numpy())

print(len(list(batched_ds_test.as_numpy_iterator())))
for batch in batched_ds_test.take(1):
  print(batch[0].shape)

### Generator Padded targets
for batch in batched_ds.take(1):
  print(batch[3].numpy())
  print(batch[1].numpy())

## map/collate func

def collate_fn(input, target, input_len, target_len):
  # print(input.eval(session=tf.compat.v1.Session()))
  inputs_pad = []
  inputs_len = [] # same as input_len
  targets_pad = []
  targets_len = []
  
  for i in range(len(input)):
    utter_len = input_len[i]
    real_utter = input[i][:utter_len]
    inputs_pad.append(real_utter)

    trans_len = target_len[i]
    real_trans = target[i][1:trans_len] # ignore '<sos>'
    targets_pad.append(real_trans)
    targets_len.append(len(real_trans)) # tarns_len - 1
  
  # (B, T, F/C)
  padded_seqs = tf.keras.preprocessing.sequence.pad_sequences(inputs_pad, padding='post', dtype='float32')
  padded_targets = tf.keras.preprocessing.sequence.pad_sequences(targets_pad, padding='post', dtype='int32')
  # print(type(padded_seqs), type(padded_targets), type(input_len), type(targets_len))
  return tf.convert_to_tensor(padded_seqs), tf.convert_to_tensor(padded_targets), input_len, tf.convert_to_tensor(targets_len)

result = batched_ds.map(lambda input, target, input_len, target_len : tf.py_function(func=collate_fn, inp=[input, target, input_len, target_len], Tout=[tf.float32, tf.int32, tf.int32, tf.int32]))   # batched_ds.map(collate_fn)

result_train = batched_ds_train.map(lambda input, target, input_len, target_len : tf.py_function(func=collate_fn, inp=[input, target, input_len, target_len], Tout=[tf.float32, tf.int32, tf.int32, tf.int32]), num_parallel_calls=tf.data.AUTOTUNE,
    deterministic=False)
print(len(list(result.as_numpy_iterator())))

print(len(list(result_train.as_numpy_iterator())))

## DEBUG
### Compare first utterance
for d, b1, b2 in zip(speech_dev[:32], batched_ds.take(1), result.take(1)): #First batch
  print(b1[0].shape)
  print(b2[0].shape)
  print(b1[0][0].numpy())
  print(b2[0][0].numpy())
  diff = b1[0][0].numpy() == b2[0][0].numpy()
  print(diff)
  print(len(np.where(diff == False)[0]))

  # original
  print(d)
  utter = b2[0][0].numpy()
  # print(utter[:d.shape[0]])
  print(utter[:b2[2].numpy()[1]])
  diff_ = d == utter[:b2[2].numpy()[0]] # get utterence_len for first utterence
  print(diff_)
  print(len(np.where(diff_ == False)[0]))

## Debug
## Check if target length include '<eos>' but exclude '<sos>'

for b in result.take(1): #First batch
  print(b[1].shape)
  print(b[3].shape)
  print("First Trans: ", b[1][0])
  print("First Trans len: ", b[3][0].numpy())
  print("# Paddings in First Trans target: ", tf.reduce_sum(tf.cast(b[1][0] > 0, tf.int32)))
  print(np.sum(b[1][0] > 0))

print("Type of Trainning set: {}".format(type(result_train)))
print(type(batched_ds_train))
print(type(ds_train))

"""### Model Structure

### Utilities, Sanity Check
"""

# Helper, Debug func
def inspect_wieghts(model):
  ws = model.get_weights()
  train_vars = model.trainable_variables
  print(type(ws))
  print(len(ws))

  num_vars = 0

  for w, var in zip(ws, train_vars):
    print("Variable: "+var.name)
    print(w.shape)
    print(w)
    cur_num_vars = 1
    for i in range(len(w.shape)):
      cur_num_vars = cur_num_vars * w.shape[i]
    num_vars  = num_vars + cur_num_vars
  print("Total Trainable variables: ", num_vars)



"""### Encoder"""

# One Example batch (B=32), from dev dataset
example_batch = next(iter(result))
print(example_batch[0].shape)
print(example_batch[1].shape) # (B, max taraget length)
print()

"""#### Pyramidal BiLSTM"""

## tf.function performance
pblstm_signature = [
    ## This based on current encoder structure: 
    ### TODO: manage the magic number: '512
    tf.TensorSpec(shape=(None, None, 512), dtype=tf.float32), # tf.float32, tf.int32 used while generating Dataset
    # Can't use the raw utterance input F=40, given we will need to stack multiple pblstm
    tf.TensorSpec(shape=(None, ), dtype=tf.int32),
]

'''
  @param vocab_size: dictionary size
  @states each state should [B, dec_hidden]
'''


class pBLSTM(tf.keras.layers.Layer):
  def __init__(self, hidden_dim):
    super(pBLSTM, self).__init__()
    
    self.hidden_dim = hidden_dim
    ##________ Bi-LSTM layer ------- ##
    self.lstm = L.LSTM(self.hidden_dim, return_sequences=True, return_state=True, name='pBLSTM_lstm')
    # outputs of the forward and backward RNNs will be combined using default: concatenate
    self.blstm = L.Bidirectional(self.lstm) # 2*hidden_dim

  # @tf.function(experimental_relax_shapes=True) # This could remove retracing... but it's still slow...
  # @tf.function()
  # @tf.function(input_signature=pblstm_signature) # This remove retracing, but it's even 20ms slower than the 'exp_relax_shape' trick every 10 batches
  def call(self, x_padded, x_lens):
    '''
    param x_padded: padded input, (B, T_max, F)
    param x_lens: actual senquence length (B, ) __TODO
    '''
    ## TF Function RETRACING DEBUG
    # print('Tracing with', x_padded)
    # print("Type of Input: {}; type of Input lens: {}".format(type(x_padded), type(x_lens)))

    # Debug
    # if debug_mode:
    #   print("Input Batch Shape: ", x_padded.shape)
    #   print("Runtime Input shape: ", tf.shape(x_padded))
    #   print("Runtime sequence shape: ", tf.shape(x_padded)[1])
    '''
      > In a tf.function or when building a model using tf.keras.Input, they return the build-time shape of the tensor, which may be partially unknown.
      Tensor.shape: The returned tf.TensorShape is determined at build time, without executing the underlying kernel. It is not a tf.Tensor. 
      If you need a shape tensor, either convert the tf.TensorShape to a tf.constant, 
      or use the tf.shape(tensor) function, which returns the tensor's shape at execution time.
    '''
    # chop off extra odd timestamp
    # x_padded = x_padded[:, :(x_padded.shape[1] // 2) * 2, :] # (B, T_max*, F)
    x_padded = x_padded[:, :(tf.shape(x_padded)[1] // 2) * 2, :] # (B, T_max*, F)
    # print("Chop off :", x_padded.shape)

    # reshape to (B, T_max*/2, 2*F)
    ## Output shape of 'Reshape': (batch_size,) + target_shape
    # x_paird = L.Reshape(target_shape=(x_padded.shape[1] // 2, x_padded.shape[2] * 2))(x_padded)
    # x_paird = L.Reshape(target_shape=(tf.shape(x_padded)[1] // 2, tf.shape(x_padded)[2] * 2))(x_padded)
    ### Temporrary solution using shape inference
    #### the sequence shape (T_max for current batch) could be unknown during execution (None, build-time shape)
    x_paird = L.Reshape(target_shape=(-1, x_padded.shape[2] * 2))(x_padded)
    # x_paird = L.Reshape(target_shape=(-1, tf.shape(x_padded)[2] * 2))(x_padded)

    reduced_lens = x_lens // 2 # we do the 'chop off'/discard earlier

    # print("REshaped: ", x_paird.shape)

    # Output of Nets, [Forward Net States pair], [Backward Net States pair]
    ### Notice hb, cb corresponding to T=0 in Forward Net $$$
    output, hf, cf, hb, cb = self.blstm(x_paird) # (B, T_max*/2, 2*H)
    
    # return the final output ( forward and backward RNNs) for now
    return output, hf, cf, hb, cb, reduced_lens

## Dev
# l = [1, 2, 3]
# print(l)
# print(l[:-1])

t = tf.constant([1, 2, 7, 8, 9, 10, 11, 12], shape=[1, 4, 2])
print(t)
print(tf.reshape(t, [1, -1, 4]))

blstm = pBLSTM(hidden_dim=2)
# blstm.summary()

## Debug length chop off
ex_input = tf.fill([32, 101, 40], 1)
ex_input = tf.cast(ex_input, dtype=tf.float32)
print(ex_input.shape, ex_input.dtype)

ex_out = blstm(ex_input, tf.repeat(25, 32))

print(len(ex_out))
print(ex_out[0].shape)
print(ex_out[5].shape)
# reduced lens
print(ex_out[5])

# DEBUG
example_pblstm_output = blstm(example_batch[0], example_batch[2])

print(example_pblstm_output[0].shape)

# blstm.summary()
inspect_wieghts(blstm)

# example_output, example_h, example_c = encoder(example_batch[0])
print(type(example_pblstm_output))
print ('Encoder output shape: (batch size, sequence length, units/enc_hidden) {}'.format(example_pblstm_output[0].shape))
print ('Forward bLSTM h vecotr shape: (batch size, units) {}'.format(example_pblstm_output[1].shape))
print ('Forward bLSTM c vector shape: (batch size, units) {}'.format(example_pblstm_output[2].shape))
print ('Backward bLSTM h vecotr shape: (batch size, units) {}'.format(example_pblstm_output[3].shape))
print ('Backward bLSTM c vector shape: (batch size, units) {}'.format(example_pblstm_output[4].shape))

print('Reduced Lens shape: (batch_size) ', example_pblstm_output[5].shape)
print('Reduced Lens: ', example_pblstm_output[5])

print('Last Feature output of LSTM')
print(example_pblstm_output[0][:, -1, :])

print('Forward hidden state of last timestep')
print(example_pblstm_output[1])

print('Backward hidden state of \'last\' timestep')
print(example_pblstm_output[3])

"""## Encoder"""

class Encoder(tf.keras.Model):
  def __init__(self, hidden_dim=256, key_size=128, value_size=128):
    super(Encoder, self).__init__()
    self.enc_units = hidden_dim
    self.value_size = value_size
    self.key_size = key_size
    

    ##________ first Bi-LSTM layer in Encoder ------- ##
    ## bottom BLSTM layer
    self.lstm_1 = L.LSTM(self.enc_units, return_sequences=True, return_state=True, name='Encoder_bilstm') 
    self.blstm_1 = L.Bidirectional(self.lstm_1) # (B, T, hidden * 2)

    ## 3 Layers of piramid-BLSTM
    ### to reduce time resolution 2^3 = 8 times; This is critical to allow
    ### the Attention model to extract the relevant info from a smalle number of time-steps
    ### The deep-arch also allows the model to learn nonliner feature representation of the data
    self.pblstm_1 = pBLSTM(hidden_dim=self.enc_units) # (B, T/2, hidden * 2)
    self.pblstm_2 = pBLSTM(hidden_dim=self.enc_units)
    self.pblstm_3 = pBLSTM(hidden_dim=self.enc_units) # (B, T/8, hidden * 2)

    ## Key && Value Projections
    self.key_proj = L.Dense(self.key_size, name='enc_key_proj') # (B, T, V/K)
    self.value_proj = L.Dense(self.value_size, name='enc_value_proj') # (B, T, V/K)

    self.relu = L.LeakyReLU(alpha=1e-2)


  def call(self, x_padded, x_lens, debug_mode=False):
    '''
    param x_padded: padded input, (B, T_max, F)
    param x_lens: actual senquence length (B, ) __TODO
    '''

    # (B, T, hidden*2)
    # x_initial, _, _ = self.lstm_1(x_padded)
    x_initial, _, _, _, _ = self.blstm_1(x_padded) 

    if debug_mode:
      print("Transformed LSTM output: ", x_initial.shape)

    x, _, _, _, _, reduced_lens = self.pblstm_1(x_initial, x_lens)
    x, _, _, _, _, reduced_lens = self.pblstm_2(x, reduced_lens)

    # (B, T/8, hidden*2)
    x, _, _, _, _, reduced_lens = self.pblstm_3(x, reduced_lens)

    # TODO: separate key projections
    key = self.key_proj(x) # (B, T, K)
    value = self.value_proj(x) # (B, T, V)

    key_act = self.relu(key)
    value_act = self.relu(value)

    return value_act, key_act, reduced_lens
    # return value, key, reduced_lens
    # return value, reduced_lens # shared key && value proj

## DEBUG
encoder_test = Encoder()

ex_input = tf.fill([32, 101, 40], 1)
ex_input = tf.cast(ex_input, dtype=tf.float32)
print(ex_input.shape, ex_input.dtype)

ex_out = encoder_test(ex_input, tf.repeat(25, 32))

print(ex_out[0].shape) # value
print(ex_out[1].shape)
print(ex_out[2]) # 25/2 = 12 (chop off...) 12/2 = 6 6 /2 = 3

print(ex_out[0])
print(ex_out[1])

"""### Attention"""

## Dev
# a = tf.fill([2, 3, 3], 2)
a = tf.constant([[1, 2, 1], [3,2,4], [2, 1, 1]])
a = tf.reshape(tf.stack([a, a], axis=0), [2, 3, 3])
print(a)
b = tf.constant([[1, 2, 1], [3, 4,2 ]])
print(b)
b = tf.expand_dims(b, axis=2)
print(b)

c = tf.squeeze(tf.matmul(a, b))

print(c)

d = tf.nn.softmax(tf.cast(c, tf.float32))
print(d)

print(tf.reduce_sum(d, axis=1))

'''
 TODO: 
'''
class Attention(L.Layer):
  def __init__(self):
    super().__init__()
    
    # TODO Keras Attention
    # self.attention = tf.keras.layers.AdditiveAttention()

  def call(self, query, value, key, lens, debug_mode=False):
    '''
    :param query: (B, dec_hidden) decoder hidden state for current timestamp, s_i
    :param value: (B, T_max, enc_size) encoder high level feature representation, 
                  key && value projections for now (TODO), h
    :param key: (B, T_max, key_size) 
    :param lens: (B, ) utterrance lens for current batch
    : TODO, currently dec_hidden == enc_size for simple scalar dot
    '''
    # print("Query Size: ", query.shape)
    # print("Value size: ", value.shape)
    # compute the energy
    # (B, T_max), scalar enery ei,u for each input timestep u, under current decoder step i
    ## pass in 'axis=' to tf.squeeze, remove only the current transcript ts dimension, which is 1. 
    ## - this is to prevent squeezing batch dimension when B==1
    ## The input speech signals can be hunderds to thousands of frames long, non-compressed LSTM would converge slowly and make it hard for
    ## the Listener to extract relevant info from a large # of utter ts
    # energy = tf.squeeze(tf.matmul(value, tf.expand_dims(query, axis=2)), axis=2)

    # Key, Query scalar product
    energy = tf.squeeze(tf.matmul(key, tf.expand_dims(query, axis=2)), axis=2)

    # Generate the mask; disregard the padded position in H (B, T_max, value_size)
    max_len = value.shape[1]


    # (1, T_max) (B, 1) -> (B, T_max)
    ## Mask all non-padded positions
    mask = tf.expand_dims(tf.range(0, max_len), axis=0) < tf.expand_dims(lens, axis=1)

    mask = tf.cast(mask, dtype=tf.float32)
  
    # print("Energy (B, T_max): ", energy.shape)

    # TODO: masking the padded ts
    # Attention vector, softmax, default axis=-1
    # (B, T_max)
    attention = tf.nn.softmax(energy)

    masked_attention = attention*mask

    # temp_sum = tf.reduce_sum(masked_attention, axis=1, keepdims=True)
    # (B, T_max)
    norm_masked_attention = masked_attention / tf.reduce_sum(masked_attention, axis=1, keepdims=True)

    if debug_mode:
      print("Padded Attention: ", attention)
      print("Mask: ", mask)
      print("Masked Attention: ", masked_attention)
      print("Normalized Attention: ", norm_masked_attention)
      print("Temp Sum ", temp_sum)

    

    # Context vectir c_i
    # value same as key bere
    # (B, value_size) = (B, 1, T_max) x (B, T_max, enc_size)
    # context = tf.squeeze(tf.matmul(tf.expand_dims(attention, axis=1), value), axis=1)
    context = tf.squeeze(tf.matmul(tf.expand_dims(norm_masked_attention, axis=1), value), axis=1)

    return context, norm_masked_attention

## DEV Attention Mask

np.exp(-1e9)

max_len = example_batch[0].shape[1]

print(example_batch[0].shape)
print(example_batch[2].shape)
print(max_len)

# (1, L_max) (B, 1)
a = tf.expand_dims(tf.range(0, max_len), axis=0)
b = tf.expand_dims(example_batch[2], axis=1)
c = a >= b # mask all padded position

print(a)
print(b)
print(c)
print(tf.reduce_sum(tf.cast(c, tf.int32), axis=1))

# # B x L_Max
# lens_m = tf.repeat(tf.expand_dims(tf.range(0, max_len), axis=0), repeats=b_size, axis=0)
# # print(lens_m)

# # B x L_Max
# lens_e = tf.repeat(tf.expand_dims(target_lens, axis=1), repeats=max_len, axis=1)
# # print(lens_e)

# mask = lens_m < lens_e
# # print(mask)
# mask = tf.cast(mask, dtype=tf.float32)

## DEBUG
example_batch[0].shape
print(example_batch[0][0])
print(example_batch[2][0])
print(example_batch[0][0][:example_batch[2][0]].shape)

attention = Attention()

test_lens = tf.constant([2, 4])
print(test_lens)
## Debug
ex_query = tf.fill([2, 4], 1.0)
ex_value = tf.fill([2, 5, 4], 3.0)
ex_key = tf.fill([2, 5, 4], 4.0) # (B, T, k/v/q)
att_out, att = attention(ex_query, ex_value, ex_key, test_lens)

print(att_out)
print(att.shape)
print(tf.reduce_sum(att, axis=1))
print(att)

# Dev
a = tf.constant([1, 2, 3, 4, 5, 6], shape=[1, 2, 3])
# print(a)
b = tf.constant([7, 8, 9, 10, 11, 12], shape=[1, 3, 2])

tf.matmul(a, b)

print("raw query: ", ex_query.shape)
e_query = tf.expand_dims(ex_query, axis=2)

print(e_query)

tf.matmul(ex_value, e_query)

example_ts_target = example_batch[1][:, 0]
print(example_batch[1].numpy())
print(example_ts_target.numpy())

"""### Decoder

#### Module Decoder
"""

## Debug
example_batch[1].shape

'''
  @param vocab_size: dictionary size
  @param dec_hidden: each state should [B, dec_hidden], TODO: same as encoder value projection size for now
'''


class Decoder(tf.keras.Model):
  def __init__(self, vocab_size, embed_dim, dec_hidden, query_size=128):
    super(Decoder, self).__init__()
    
    self.dec_units = dec_hidden
    self.embedding = L.Embedding(vocab_size, embed_dim)
    self.vocab_size = vocab_size
    self.query_size = query_size # Match Encoder Key Projection for easy dot product

    ##________ Step LSTM Cell in Decoder ------- ##
    ## Input size: [E, C/V]
    self.lstm1 = L.LSTMCell(dec_hidden, name='dec_lstm_1')
    self.lstm2 = L.LSTMCell(query_size, name='dec_lstm_2') # TODO: have a dedicated query projection layer 

    self.attention = Attention()

    # char distribution
    self.fc = L.Dense(vocab_size)


  # @tf.function
  # TODO: the input sequence length could be unknown during execution (None), need a RNN cell module to optimize this part
  def call(self, x, value=None, key=None, hidden=None,  encoder_lens=None, ini_context=None, teacher_force=False, teacher_forcing_rate=0.1, debug_mode=False, if_generate=False):
    '''
    :param x: (B, L_max) [ground-trouth, D] input transcrip sequence
    :param value: (B, T_max, enc_size); high-level feature representation of encoder projection, h
    :param key: (B, T_max, key_size); separate projection of encoder high level representation H
    :param encoder_lens: (B, ); actual lens of utterences (might be shrinked in)
    :param ini_context; c-1 or c(i-1), not needed during generate or training mode
    :TODO, separately projected key of encoder
    :param hidden: s-1, tuple of (hidden_state, cell_state)
    :     update: list of state tuple (hidden_state, cell_state) for each decoder rnn layer
          TODO: should hide this parameters
    '''

    ## TODO: Teacher Forching && Gumbel Noise

    # print("Input Transcripts Shape: ", x.shape)
    batch_size = x.shape[0]
    L = x.shape[1] # max transcript length for current 
    
    hidden_states = hidden
    if hidden == None:
      # Initialize Hidden States with zero-filled tensor
      h1 = [tf.zeros((batch_size, self.dec_units)), tf.zeros((batch_size, self.dec_units))]
      h2 = [tf.zeros((batch_size, self.query_size)), tf.zeros((batch_size, self.query_size))]
      hidden_states = [h1, h2]

    # if debug_mode:
    #   print("Hidden states: ", hidden_states)
    

    # (B, L_max, E) 
    # the '<sos>' embedding is not included
    x = self.embedding(x)
    if debug_mode:
      print("Input Embedding: ", x)

    logits = [] # TODO,  use tf.TensorArray to accumulate results from a dynamically unrolled loop.

    # (B, V)
    char_dis = tf.zeros([batch_size, self.vocab_size])

    # Sampled Attention Matrix (L_max, T_max) for one instance of the batch
    ## pick the first one for now
    attention_sample = []

    # The intial contexct ci-1 (B, C/V)
    ### initialize use the first value of the encoder feature representation H sequences
    #### This seems bad...
    ### TODO: blend with the initial rnn hidden states?
    # if debug_mode:
      # print("Encoder H: ", value)
    # context = value[:,0,:] # H[0]

    ## C-1
    ## If no initial context provided use initial context of 0's
    context = tf.zeros((batch_size, tf.shape(value)[2]))
    if ini_context != None:
      context = ini_context

    if debug_mode:
      print("c_-1: {}, type: {}".format(context, type(context)))

    for i in range(L):
      # for each timestamp
      ## 1. Get Input Transcript embedding (B, E)
      # if i == 0:
      #   char_embed = tf.zeros([batch_size], tf.float32)
      # else:
      #   char_embed = x[:, i-1, :] 
      
      # <sos> included, <eos> not included; TODO: this need to be handled outside for now

      if teacher_force: #Teacher forcing enabled training mode
        teacher_forcing = True if np.random.random_sample() > teacher_forcing_rate else False
        # Use Ground Truth
        if teacher_forcing:
          if debug_mode:
            print("Using input ground truth")
          char_embed = x[:, i, :]
        else:
          # Apply Gumbel Noise to simulate a sample from discrete distribution
          if i==0:
            if debug_mode:
              print("Using input ground truth")
            # no predicted char distribution yet
            char_embed = x[:, i, :]
          else:
            # the raw logits from previvous step: (B, V)
            ## temperature as 1,
            dist = tfp.distributions.RelaxedOneHotCategorical(1, logits=char_dis)

            # (B, V)
            gumbel_samples = dist.sample()

            # (B, E)
            char_embed = self.embedding(tf.math.argmax(gumbel_samples, axis=-1))

            if debug_mode:
              print("Sample from Char Dist with Gumbel Noise")
              print("Gumbel samples shape: {}, \n Sanity check on row sums: {} \n Char Embedding shape: {}".format(gumbel_samples.shape, tf.reduce_sum(gumbel_samples, axis=-1).numpy(), char_embed.shape))

      else:
        if if_generate==False: # Simple training using ground truth
          # (B, E), for current ts
          if debug_mode:
            print("Using input ground truth")
          char_embed = x[:, i, :]
        else:
          if i==0:
            if debug_mode:
              print("Using input ground truth")
            # no predicted char distribution yet
            char_embed = x[:, i, :]
          else:
            # the raw logits from previvous step: (B, V)
            # (B, E)
            char_embed = self.embedding(tf.math.argmax(char_dis, axis=-1))


      if debug_mode:
        print("TS: {}, embedding used: {}".format(i, char_embed))

      ## 2. pass through rnn cell
      ### out/query (B, dec_hidden)
      ### Decoder input (to the first rnn cell) at every timestep is the concatenated character embedding and attention context vector 
      ### si = RNN(si-1, [yi-1, ci-1]))
      if debug_mode:
        print("c_i-1: {}, type: {}".format(context, type(context)))
      ### concatenate embedding and context vector: (B, E|value_size/context_size)
      dec_rnn_input = tf.keras.layers.concatenate([char_embed, context], axis=-1)
      # if debug_mode:
        # print("RNN Layers input Size: ", dec_rnn_input.shape)
        # print("Context c_i-1: ", context)

      # (B, dec_hidden)
      lstm1_out, lstm1_states = self.lstm1(inputs=dec_rnn_input, states=hidden_states[0]) # TODO, pass in states tuple for each rnn layer
      
      ## (B, dec_size)
      hidden_states[0] = lstm1_states

      ## rnn_output: current just the querysize: (B, query_size)
      out, lstm2_states = self.lstm2(inputs=lstm1_out, states=hidden_states[1])

      hidden_states[1] = lstm2_states

      # if debug_mode:
      #   # Out == states[0]
      #   print("LSTM out", lstm1_out.shape)
      #   print(lstm1_out.numpy())
      #   print(type(lstm1_states))
      #   print(len(lstm1_states))
      #   print(lstm1_states[0])
      #   print(lstm1_states[1])

      #   print("LSTM final out: ", out)
      #   print(lstm2_states[0])
      #   print(lstm2_states[1])

      ## 3. get context vector using query and key
      ### context: (B, value_size/enc_size/dec_size)
      ### attention: (B, T_max)
      # print("Compute attention for ts: {}".format(i))
      # print("Enc value projection: ", value.shape)
      context, attention = self.attention(out, value, key, encoder_lens)

      ## For Sanity Check
      attention_sample.append(attention[0])

      # print(context.shape)
      # print(context)
      # print(tf.reduce_sum(attention, axis=1))

      ## 4. get character distribution (Final Linear layer)
      ### concatenate rnn output and context vector: (B, dec_size|value_size)
      cat = tf.keras.layers.concatenate([out, context], axis=-1)
      # print(cat.shape)

      # (B, vocab_size)
      char_dis = self.fc(cat)
      # print(char_dis.shape)
      # print(tf.reduce_sum(char_dis, axis=1))

      # print(char_dis.shape)
      # (B, 1, vocab_size)
      logits.append(tf.expand_dims(char_dis, axis=1))
      
    # (B, L_max, vocab_size)
    output = tf.concat(logits, axis=1)
    # print(output.shape)
    # output, h, c = self.lstm_layer(x, initial_state = hidden)
    # dis = self.fc(output)
    # return dis, h, c

    # return lstm next hidden state && cell state for each element in the batch: (B, dec_H)
    #  use stack to concatenate along a new axis 
    return output, hidden_states, tf.stack(attention_sample, axis=0), context

## DEV
tf.repeat(50, 32)

## Teacher Forcce
decoder_tf = Decoder(len(LETTER_LIST), 100, 128)
hidden_test = [tf.zeros([32, 128]), tf.zeros([32, 128])]
tf_out, tf_hidden, tf_att_sample = decoder_tf(example_batch[1], value=tf.ones([32, 201, 128]), key=tf.ones([32, 201, 128]), hidden=None, encoder_lens = tf.repeat(50, 32), teacher_force=True, teacher_forcing_rate=1.0, debug_mode=False)

# Debug
decoder_ = Decoder(len(LETTER_LIST), 100, 128)
example_dec_output, example_dec_next_states, att_sample= decoder_(example_batch[1], value=tf.ones([32, 201, 128]), key=tf.ones([32, 201, 128]),hidden=None, encoder_lens=tf.repeat(50, 32), debug_mode=True)

# DEV
## GUMBEL NOISE
t = example_dec_output[0:1,0:1,:]
print(t.shape)
print("Raw logits: ", t)

dist = tfp.distributions.RelaxedOneHotCategorical(1, logits=t)

# generate sample tensor of same shape as logits from the Gumbel-Softmax distribution.
##  returned samples will be probability distributions that sum to 1 across dim
s = dist.sample()
print(s)
print(tf.reduce_sum(s, axis=-1))

print(tf.math.argmax(s, axis=-1))

## Attention Sample for Plotting
print(len(att_sample))
print(att_sample[0].shape)
print(att_sample[3])

# sa = tf.stack(att_sample, axis=0)

# print(sa[3])
# print(tf.reduce_sum(sa[3]))



print(example_dec_output.shape) # ï¼ˆB, T_max, V)
for states in example_dec_next_states:
  print ('Decoder h vecotr shape: (batch size, dec_units) {}'.format(states[0].shape))
  print ('Decoder c vector shape: (batch size, dec_units) {}'.format(states[1].shape))

"""#### E2E test"""

print("Input Utterence: ", example_batch[0].shape)
print("Target Transcripts: ", example_batch[1].shape)
# encoder = pBLSTM(hidden_dim=64)
# The Sophiscated Encoder with Multiple pBLSTM
encoder = Encoder(hidden_dim=256, value_size=128, key_size=128)

example_enc_output = encoder(example_batch[0], example_batch[2])

print(example_enc_output[0].shape) # (B, T_max/8, value_size)
# print(example_enc_output[1].shape) # (B, T_max/8, key_size)
# print(example_enc_output[1].shape)
# print(example_enc_output[2].shape)

# dec_ini_h = tf.concat([example_enc_output[1], example_enc_output[3]], axis=1)
# dec_ini_c = tf.concat([example_enc_output[2], example_enc_output[4]], axis=1)
# print(dec_ini_h.shape)
# print(dec_ini_c.shape)

# Actual sequence lengths of encoder hidden representations H
reduced_enc_lens = example_enc_output[2] # if key is present
# reduced_enc_lens = example_enc_output[1]
print(reduced_enc_lens.shape) # (B,)
# print(example_enc_output[0].numpy()[:, -1, :].shape)
# print(example_enc_output[1].numpy())

np.set_printoptions(threshold=100)

# decoder = Decoder(len(LETTER_LIST), 100, 128)
decoder = Decoder(len(LETTER_LIST), embed_dim=256, dec_hidden=512, query_size=128) # Structure proposed in the paper

# input 1: target transcript (B, L)
# input 2: encoder value proj (B, T*, E_H), encoder feature representation
# input 3: initial hidden states for encoder LSTM(s)
## Initial Hidden states list as zero filled
# initial_hidden = [dec_ini_h, dec_ini_c]
initial_hidden = None
ex_dec_output, ex_dec_next_states, ex_dec_att_sample, _ = decoder(example_batch[1], value=example_enc_output[0], key=example_enc_output[1], hidden=initial_hidden, encoder_lens=reduced_enc_lens, debug_mode=False) # Separate key and value projs
# ex_dec_output, ex_dec_next_states, ex_dec_att_sample = decoder(example_batch[1], value=example_enc_output[0],  hidden=initial_hidden, encoder_lens=reduced_enc_lens, debug_mode=False)


print(ex_dec_output.shape)
print(ex_dec_output.numpy()[0])

# hidden states for all Decoder RNN layer
for layer in ex_dec_next_states:
  print(layer[0].shape)
  print(layer[1].shape)

print(type(ex_dec_next_states))

# print(ex_dec_att_sample[0])
print(tf.reduce_sum(tf.cast(ex_dec_att_sample[0] > 0.0, tf.int32)))
print(reduced_enc_lens[0]) # T_actual/8 for the first utterencee
print(example_enc_output[0].shape) # (B, T_reduced, value_size)

# Plot the dummy attention map
plt.matshow(ex_dec_att_sample)
plt.show()

###[Optional] Load Existing model weights
local_dir = './colab_storage'
drive_dir = './drive/MyDrive'
encoder_train_cp_dir = local_dir + '/LAS/train/weights/encoder'  # './drive/MyDrive/LAS/weights/encoder'
decoder_train_cp_dir = local_dir + '/LAS/train/weights/decoder' #'./drive/MyDrive/LAS/weights/decoder'

###[Optional] Load Existing under-training model checkpoints/weights
encoder.load_weights(encoder_train_cp_dir)
decoder.load_weights(decoder_train_cp_dir)

"""##### (Check) Initial States before training"""

# encoder.summary()
inspect_wieghts(encoder)

decoder.summary()
inspect_wieghts(decoder)

l_t = [1, 2, 3]
l_t[:-1]

"""## Train"""

# @tf.function
def plot_grad_flow(grads_and_vars):
  '''
  input (gradients, trainable_variables)
  '''
  grads = grads_and_vars[0]
  vars = grads_and_vars[1]

  ave_grads = []    
  max_grads= []    
  layers = [] 

  print("# variables {}, # grads {}".format(len(vars), len(grads)))

  for grad, var in zip(grads, vars):
    name = var.name
    layers.append(name)

    # reduce over all dims/elements                
    ave_grads.append(tf.reduce_mean(tf.abs(grad)))     
    max_grads.append(tf.reduce_max(tf.abs(grad)))

  plt.clf()
  plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color="r")    
  plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color="b")    
  plt.hlines(0, 0, len(ave_grads)+1, lw=2, color="k" )    
  plt.xticks(range(0,len(ave_grads), 1), layers, rotation="vertical")    
  plt.xlim(left=0, right=len(ave_grads))    
  # plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions    
  plt.xlabel("Layers")
  plt.ylabel("average gradient")    
  plt.title("Gradient flow")    
  #plt.tight_layout()    
  plt.grid(True)    
  # plt.legend([Line2D([0], [0], color="c", lw=4),
  #             Line2D([0], [0], color="b", lw=4),
  #             Line2D([0], [0], color="k", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])    
  return plt

def loss_function(real, pred, target_mask):
  # loss always reduce -1 dimension
  # real shape = (BATCH_SIZE, max_length_output)
  # pred shape = (BATCH_SIZE, max_length_output, target_vocab_size )
  # target_mask: (B, T_max)
  # print("Target Shape ", real.shape)
  # print("Logits Shape ",pred.shape)
  # print("Target Lens ", target_lens.shape)

  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')
  # (BATCH_SIZE, max_length_output)
  loss = cross_entropy(y_true=real, y_pred=pred)
  # print("Loss Matrix Shape ", loss.shape)
  ## TODO: Mased Loss
  # mask = tf.logical_not(tf.math.equal(real,0))   #output 0 for y=0 else output 1
  # mask = tf.cast(mask, dtype=loss.dtype)  
  # loss = mask* loss

  # # Mask based on target lens
  # # TODO: 'None values not supported.'
  # max_len = real.shape[1]
  # b_size = real.shape[0]

  # # B x L_Max
  # lens_m = tf.repeat(tf.expand_dims(tf.range(0, max_len), axis=0), repeats=b_size, axis=0)
  # # print(lens_m)

  # # B x L_Max
  # lens_e = tf.repeat(tf.expand_dims(target_lens, axis=1), repeats=max_len, axis=1)
  # # print(lens_e)

  # mask = lens_m < lens_e
  # # print(mask)

  # mask = tf.cast(mask, dtype=loss.dtype)
  # # print(mask)

  # # print('Mask sum at transcript i: {}, actual transcript length: {}'.format(tf.reduce_sum(mask[5]), target_lens[5]))
  masked_loss = target_mask * loss

  # return average loss per elements
  # final_loss = tf.reduce_mean(masked_loss)
  # return final_loss, tf.reduce_mean(loss)

  # return sum of losses of B x L_Max
  return tf.reduce_sum(masked_loss), tf.reduce_sum(loss)

print(1e-3)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)
# optimizer = tf.keras.optimizers.Adam()

### TODO: under tf.function, get runtime sequence shape (errors under 'None' runtime value, both L_max and T_max)
# @tf.function( experimental_relax_shapes=True)
def train_step(input, target, input_lens, target_mask, tf_rate=0.1):
  # print("=========== Inspecting weights of encoder")

  # inspect_wieghts(encoder)

  # print("=========== Inspecting weights of decoder")

  # inspect_wieghts(decoder_)

  loss = 0

  # print(input.shape)
  # print(target.shape)
  # print(target.numpy())


  with tf.GradientTape() as tape:
    # enc_output, enc_h, enc_c =  encoder(input)

    enc_output = encoder(input, input_lens)

    # dec_ini_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
    # dec_ini_c = tf.concat([enc_output[2], enc_output[4]], axis=1)

    # ini_hidden = [dec_ini_h, dec_ini_c]
    ini_hidden = None # use zero-filled initial hidden states

    reduced_enc_lens = enc_output[2] # separate key && value
    # reduced_enc_lens = enc_output[1]

    # attach previous removed '<sos>' #TODO, remove this
    # Ignore '<eos>'
    # But still keep the '<eos>' token in target, - we still need to learn when to end the sequence 
    dec_input = tf.pad(target[:, :-1], [[0, 0], [1, 0]], "CONSTANT", constant_values=letter2index['<sos>'])
    # real = target[ : , 1: ]         # ignore <start> token
    # target already have '<sos>' removed

    ## $$ use decoder final state as initial states for decoder LSTM cell here
    ## s and h sharing same size, so s-1 = hN
    ## Use encoder direct LSTM output features as 'value' , enc_H == dec_H for sclar dot during attention computation
    ### Connecting Encoder and Decoder here to avoid `WARNING:tensorflow:Gradients do not exist for Encoder Variables when minimizing the loss.`

    # pred, dec_h, dec_c = decoder(dec_input, [enc_h, enc_c]) # input targets
    ## Apply 10% teacher forcing rate
    # Separate Key and Value projection
    pred, dec_next_states, attention_sample, _ = decoder(dec_input, value=enc_output[0],  key=enc_output[1], hidden=ini_hidden, encoder_lens=reduced_enc_lens, teacher_force=True, teacher_forcing_rate=tf_rate)
    # pred, dec_next_states, attention_sample = decoder(dec_input, value=enc_output[0],  hidden=ini_hidden, encoder_lens=reduced_enc_lens, teacher_force=True, teacher_forcing_rate=tf_rate)
    
    loss, unmasked_loss = loss_function(target, pred, target_mask)

  variables = encoder.trainable_variables + decoder.trainable_variables

  # print("BackWarding: Back Prop loss.......")
  # # Calculate the gradients for encoder and decoder
  # print("Type of loss: {}, value of loss: {}".format(type(loss), loss.numpy()))

  ## returned gradieents are a list or nested structure of Tensors, one for each element in sources. same structure as sources.
  gradients = tape.gradient(loss, variables)
  optimizer.apply_gradients(zip(gradients, variables))

  return loss, unmasked_loss, (gradients, variables), attention_sample

np.set_printoptions(threshold=100)
debug_mode = False


EPOCHS = 5
data = result_train # dev dataset: result
for epoch in range(EPOCHS):
  start = time.time()
  time_cp = start
  # Epoch aggregation
  total_loss = 0
  total_words = 0 # total_labels
  # print(enc_hidden[0].shape, enc_hidden[1].shape)
  steps_per_epoch = 0

  for (batch, (inp, targ, input_lens, target_lens)) in enumerate(data):
    # print('Batch # {}'.format(batch))
    # Debug
    # print(type(inp), type(targ), type(input_lens), type(target_lens))
    # print(target_lens)
    # print("Utterence Shape: {}, Target Shape: {}; Utter lens shape: {}, Target lens shape: {}".format(inp.shape, targ.shape, input_lens.shape, target_lens.shape))
    # Generate mask before hand
    # Mask based on target lens
    # TODO: put into generate loss function
    max_len = targ.shape[1]
    b_size = targ.shape[0]

    # B x L_Max
    lens_m = tf.repeat(tf.expand_dims(tf.range(0, max_len), axis=0), repeats=b_size, axis=0)
    # print(lens_m)

    # B x L_Max
    lens_e = tf.repeat(tf.expand_dims(target_lens, axis=1), repeats=max_len, axis=1)
    # print(lens_e)

    mask = lens_m < lens_e
    # print(mask)
    mask = tf.cast(mask, dtype=tf.float32)

    # print("Mask: ", tf.cast(mask, tf.int32))
    # print("Trans Target: ", targ)
    if debug_mode:
      print('Mask sum at transcript i: {}, actual transcript length: {}, # non_padding elements in target: {}'.format(tf.reduce_sum(mask[0]), target_lens[0], np.sum(targ[0] > 0)))

    # Train Current Step
    # print("----Batch {}: train_step".format(batch))
    # Utterence Lens: (B, )
    batch_loss, batch_unmasked_loss, grads_vars, batch_att_sample = train_step(inp, targ, input_lens, mask, tf_rate=0.2)

    batch_words = tf.reduce_sum(mask)

    # [Debug]
    # print('(B x Max_L) : {} x {}, # words: {}'.format(b_size, max_len, batch_words))

    total_loss += batch_loss
    total_words += batch_words

    loss_per_word = batch_loss / batch_words
    batch_perplex = tf.math.exp(loss_per_word)

    if batch % 10 == 0:
      period_runtime = time.time() - time_cp
      time_cp = time.time()
      print('Epoch {} Batch {} Loss {:.4f}; [Debug] Unmasked Loss: {:.4f}; Loss per word: {:.4f}; Perplexity (exp of loss_per_word): {:.5f}; || Runtime CheckPoint: {:.4f}'.format(epoch + 1,
                                                   batch,
                                                   batch_loss, batch_unmasked_loss,
                                                   loss_per_word, batch_perplex,
                                                   period_runtime))
                                                  #  batch_loss.numpy())) # tf function
      # [Sanity Check x] Plot Gradient Flow
      if batch % 50 == 0:
        # TODO: move this to validation step completely?
        plt = plot_grad_flow(grads_vars)

        plt.show()

        # [Sanity Check] Plot Attention Matrix for one sample (curretly first) in the batch (Trans_lens_max x Utter/Enc_lens_max)
        plt.matshow(batch_att_sample)
        plt.show()

        # Calculate edit Distance
        ## TODO: Move to a dedicated func, with selection of inference method

        batch_edit_dist = 0.0

        enc_output = encoder(inp, input_lens)

        # dec_ini_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
        # dec_ini_c = tf.concat([enc_output[2], enc_output[4]], axis=1)

        reduced_enc_lens = enc_output[2] # Separate Key and Value projs
        # reduced_enc_lens = enc_output[1]

    
        dec_input = tf.pad(targ[:, :-1], [[0, 0], [1, 0]], "CONSTANT", constant_values=letter2index['<sos>'])
    
        pred, dec_next_states, attention_sample, _ = decoder(dec_input, value=enc_output[0], key=enc_output[1], hidden=None, encoder_lens=reduced_enc_lens, teacher_force=True, teacher_forcing_rate=1.0) # take sample from previous ts output distributions all the time
        # pred, dec_next_states, attention_sample = decoder(dec_input, value=enc_output[0], hidden=None, encoder_lens=reduced_enc_lens, teacher_force=True, teacher_forcing_rate=1.0) # take sample from previous ts output distributions all the time
        ## TODO: enable random search or beam_search during validation

        # Pred: (B, L_max, target_vocab_size )

        ## Greedy Search
        ## Predicted transcripts (B, L_max)
        pred_trans = tf.math.argmax(pred, axis=-1)

        pred_text = transform_index_to_letter(pred_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

        target_text = transform_index_to_letter(targ.numpy(), [letter2index['<eos>'], letter2index['<pad>']])

        # spell = transform_index_to_letter([best_path_raw_idx], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

        print("Target Text: {} \n Predicted Text: {}".format(target_text[0], pred_text[0]))
        
        for pred, target in zip(pred_text, target_text):
          dist = LEV.distance(pred, target)

          batch_edit_dist += dist

        print("The Average Edit distance per current batch: {:.5f}".format(batch_edit_dist/len(target_text)))

    steps_per_epoch += 1
  # # saving (checkpoint) the model every 2 epochs
  # if (epoch + 1) % 2 == 0:
  #   checkpoint.save(file_prefix = checkpoint_prefix)

  ## TODO: epoch average LEV dist?
  print('Epoch {} Loss per Batch{:.4f}, after {} steps; Epoch loss per word: {:.4f}, Epoch Perplexity: {:.5f}'.format(epoch + 1,
                                      total_loss / steps_per_epoch, steps_per_epoch, total_loss/total_words, tf.math.exp(total_loss/total_words)))
  print('Time taken for 1 epoch {} sec\n'.format(time.time() - start)) # CPU: 86s for dev_data

  ## Save the Model Checkpoints (Model Weights for now)
  print("==================Saving Model Weights...======================")

  encoder.save_weights(encoder_train_cp_dir, overwrite=True, save_format='tf')
  decoder.save_weights(decoder_train_cp_dir, overwrite=True, save_format='tf')

  # Resource Monitoring
  monitor_gpu()

  ## TODO: validation step using validation set

## Debug
# for batch in result_train:
#   print(batch[0].shape, batch[1].shape, batch[3].shape)

monitor_gpu()

# debug

inspect_wieghts(decoder)

inspect_wieghts(encoder)

"""##### Model Checkpoint"""

!ls ./drive/MyDrive/
# local
!dir colab_storage/

local_dir = './colab_storage'
drive_dir = './drive/MyDrive'
encoder_cp_dir = local_dir + '/LAS/weights/encoder'  # './drive/MyDrive/LAS/weights/encoder'
decoder_cp_dir = local_dir + '/LAS/weights/decoder' #'./drive/MyDrive/LAS/weights/decoder'

# TODO: save the model
# encoder.save('v0_1_epoch_encoder.h5')
encoder.save_weights(encoder_cp_dir, overwrite=False, save_format='tf')
# decoder.save('v0_1_epoch_decoder.h5')
decoder.save_weights(decoder_cp_dir, overwrite=False, save_format='tf')

## DEV
t = tf.constant([[1,2,3], [2,3,4], [5,6,6]])
# t = t + tf.fill(3, 33)
f = tf.fill(3, 1)
print(f)

# tf.stack([t, f], axis=0)
# tf.concat([t, f], axis=1)
tf.pad(t, [[0, 0], [1, 0]], "CONSTANT", constant_values=33)

r = tf.random.uniform(shape=[2, 3, 2])
r.numpy()

r_ = r[:, 0, :] # take the first sequence
r_.numpy()



"""## Inference/Test

###### Load/Restore Model/Model weights
"""

# # Checkpoint directories
local_dir = './colab_storage'
encoder_cp_dir = local_dir + '/LAS/weights/encoder'  # './drive/MyDrive/LAS/weights/encoder'
decoder_cp_dir = local_dir + '/LAS/weights/decoder' #'./drive/MyDrive/LAS/weights/decoder'

# inf_encoder = pBLSTM(hidden_dim=64)
inf_encoder =  Encoder(hidden_dim=256, value_size=128, key_size=128)
# inf_encoder.build(input_shape=tf.TensorShape([None, None, 40])) # Currently, you cannot build your model if it has positional or keyword arguments that are not inputs to the model,

# inf_encoder(example_batch[0])
inspect_wieghts(inf_encoder)

inf_encoder.load_weights(encoder_cp_dir)
inspect_wieghts(inf_encoder)

# inf_decoder = Decoder(len(LETTER_LIST), 100, 128)
inf_decoder = Decoder(len(LETTER_LIST), embed_dim=256, dec_hidden=512, query_size=128)
inspect_wieghts(inf_decoder)

inf_decoder.load_weights(decoder_cp_dir)
inspect_wieghts(inf_decoder)

# print(example_dec_output.shape) # ï¼ˆB, T_max, vocab_size)
# print(example_dec_output)

"""###### Load Test Data"""

test_batch = next(iter(result))
print(test_batch[0].shape)
print(test_batch[1].shape) # (B, max taraget length)

# it = iter(result)
# for b in result.take(10):
#   print(b[0].shape)

print(test_batch[1])
test_text = transform_index_to_letter(test_batch[1].numpy(), [letter2index['<eos>'], letter2index['<pad>']])

# spell = transform_index_to_letter([best_path_raw_idx], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])
print(test_text)

print(LEV.distance(test_text[0], "The bastard"))

def val(num_samples=2, max_seq=20):
  # For single Batch
  utter_input = test_batch[0] # B, U_max, F
  utter_lens = test_batch[2] # B,
  target_trans = test_batch[1] # B, T_max
  batch_size = target_trans.shape[0]
  print(utter_input.shape)
  print(target_trans.shape)

  og_trans = transform_index_to_letter(target_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']])
  for i in range(target_trans[:min(num_samples, batch_size)].shape[0]):
    utter = utter_input[i:i+1, :, :] # avoid squeezing
    utter_len = utter_lens[i:i+1]
    print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
    target = target_trans[i:i+1, :]
    print(utter.shape) # (1, U, F)
    print(utter_len.shape)
    print(target.shape) # (1, T)
    
    # Invoke Encoder
    # enc_output, enc_h, enc_c =  encoder(utter)

    enc_output = encoder(utter, utter_len)

    enc_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
    enc_c = tf.concat([enc_output[2], enc_output[4]], axis=1)

    enc_reduced_len = enc_output[5]

    print(type(enc_output))
    print(enc_output[0].shape) # 1, U*, enc_dim
    print(enc_h.shape) # 1, enc_dim
    print("Last T of enc out \n", enc_output[0].numpy()[:, -1, :])
    print("Enc Last Hidden state \n", enc_h.shape, enc_h.numpy())
    print("Enc Last Cell state \n", enc_c.shape, enc_c.numpy())
    print("Enc reduced Len(s) \n", enc_reduced_len)


    # attach previous removed '<sos>'
    # Ignore '<eos>', $$$ TODO: need to remove padding
    # dec_input = tf.pad(target[:, :-1], [[0, 0], [1, 0]], "CONSTANT", constant_values=letter2index['<sos>'])
    # print(dec_input)
    dec_input = tf.fill([1, 1], letter2index['<sos>']) # start of sequence # (1, 1)
    seq = ['<sos>']
    seq_index = [letter2index['<sos>']]
    # initial Decoder State
    # Use Encoder hidden states for now, s-1=hN
    h_state = enc_h
    c_state = enc_c

    while tf.squeeze(dec_input).numpy() != letter2index['<eos>'] and len(seq) < max_seq:
      # print(h_state.numpy())
      # print(c_state.numpy())
      # pred, dec_h, dec_c = decoder_(dec_input, [h_state, c_state]) # input targets 
      ## TODO
      pred, next_states, att_sample = decoder(dec_input, value=enc_output[0], hidden=[h_state, c_state], encoder_lens=enc_reduced_len)

      h_state = next_states[0]
      c_state = next_states[1]
      # print("Last Linear Layer :", pred.shape) # (1, 1, 35)
      # print("Hidden state of last timestamp/current :", dec_h.shape) # 1, dec_dim
      # print("Hidden Cell state of last timestamp/current: ", dec_c.shape) # 1, dec_dim
      # print(pred[-1]) # (1, 1, 35)

      print("step {}".format(len(seq)))
      print("Attention matrix (Trans len, Utter len) ", att_sample.shape)
      print("Attention Vec: ", att_sample)


      # $$ Greedy Search
      next_input =  tf.math.argmax(tf.squeeze(pred), axis=-1)
      dec_input = tf.fill([1,1], next_input)
      seq.append(index2letter[next_input.numpy()])
      seq_index.append(next_input.numpy())

      # print(tf.squeeze(pred).numpy())
      # print(seq)



    # print(utter.numpy())
    print("Input Target: ", target.numpy())
    print("Actual Transcript: ", og_trans[i])

    print("Raw Prediction sequence :", seq)
    print("Predicted Transcript: ", transform_index_to_letter([seq_index], [letter2index['<eos>'], letter2index['<pad>']]))

val(num_samples=1)



"""##### Beam Search"""

## DEV
d = {1:-0.3246, 2:-0.9185, 3:-3985, 5:-3985, 7:5}

dv = list(d.values())

print(type(dv), dv)

ds = sorted(d.items(), key=lambda x: x[1], reverse=True)

print(ds)
print(type(ds))

def prune(paths_seq, paths_idx, paths_score, paths_states, paths_contexts, beam_width=10, debug_mode=True):
  pruned_paths_seq = set()
  pruned_paths_idx = {}
  pruned_paths_score = {}
  pruned_paths_states = {}
  pruned_paths_contexts = {}
  best_path = '<eos>'

  if debug_mode:
    print("The paths scores: ", paths_score)

  score_list = list(paths_score.values())

  score_list.sort(reverse=True)

  if debug_mode:
    top_paths = sorted(paths_score.items(), key=lambda x: x[1], reverse=True)
    print("sorted scores: ", score_list)
    print("sorted paths with scores: ", top_paths)
  cutoff = score_list[beam_width] if (beam_width < len(score_list)) else score_list[-1]

  for p in paths_seq:
    if paths_score[p] > cutoff:
      if debug_mode:
        print("Path {}, with path_score: {} get selected.".format(p, paths_score[p]))
      pruned_paths_seq.add(p)
      pruned_paths_idx[p] = paths_idx[p]
      pruned_paths_score[p] = paths_score[p]
      pruned_paths_states[p] = paths_states[p]
      pruned_paths_contexts[p] = paths_contexts[p]

      # record current best scored Path
      if paths_score[p] == score_list[0]:
        best_path = p

  return pruned_paths_seq, pruned_paths_idx, pruned_paths_score, pruned_paths_states, pruned_paths_contexts, best_path

## Apply inference stage model(s)
def val_beam(num_samples=2, max_seq=20):
  # For single Batch
  utter_input = test_batch[0] # B, U_max, F
  target_trans = test_batch[1] # B, T_max
  batch_size = target_trans.shape[0]
  print(utter_input.shape)
  print(target_trans.shape)

  og_trans = transform_index_to_letter(target_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']])

  # For each Utterance (encoder input)
  for i in range(target_trans[:min(num_samples, batch_size)].shape[0]):
    utter = utter_input[i:i+1, :, :] # avoid squeezing
    print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
    target = target_trans[i:i+1, :]
    print(utter.shape) # (1, U, F)
    print(target.shape) # (1, T)
    
    # Invoke Encoder
    # enc_output, enc_h, enc_c =  encoder(utter)

    enc_output = inf_encoder(utter)

    enc_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
    enc_c = tf.concat([enc_output[2], enc_output[4]], axis=1)

    # Encoder output for current utterance, Hidden/High level representation H
    print(type(enc_output))
    print(enc_output[0].shape) # 1, U, enc_dim
    print(enc_h.shape) # 1, enc_dim
    # print("Last T of enc out \n", enc_output[0].numpy()[:, -1, :])
    # print("Enc Last Hidden state \n", enc_h.shape, enc_h.numpy())
    # print("Enc Last Cell state \n", enc_c.shape, enc_c.numpy())


    # Preparation
    path = '<sos>'
    beam_seq = set()
    beam_idx = {}
    pathscore = {}
    states = {}

    beam_seq.add(path)
    beam_idx[path] = [letter2index[path]]
    pathscore[path] = 1.0
    states[path] = [enc_h, enc_c]

    print('Initial Beam sequence: ', beam_seq)
    print('Initial Beam Idxs: ', beam_idx)


    dec_input = tf.fill([1, 1], letter2index['<sos>']) # start of sequence # (1, 1)
    seq = ['<sos>']
    seq_index = [letter2index['<sos>']]
    # initial Decoder State
    # Use Encoder hidden states for now, s-1=hN
    h_state = enc_h
    c_state = enc_c

    # while tf.squeeze(dec_input).numpy() != letter2index['<eos>'] and len(seq) < max_seq:
    for step in range(max_seq):
      # print(h_state.numpy())
      # print(c_state.numpy())
      # pred, dec_h, dec_c = decoder_(dec_input, [h_state, c_state]) # input targets 
      ## TODO

      n_beam_seq = set()
      n_beam_idx = {}
      n_pathscore = {}
      n_states = {}

      # 1. expore each path in beam
      for path in beam_seq:
        print('step {}, path: {}'.format(step, path))
        path_idx = beam_idx[path]
        print('sequence idx format: ', path_idx)

        cfin = tf.fill([1, 1], path_idx[-1])
        print('dec input: ', cfin)
        hpath = states[path]

        pred, next_states, _ = inf_decoder(cfin, value=enc_output[0], hidden=hpath)

        # print("Last Linear Layer :", pred.shape) # (1, 1, 35)
        # print('Pred :', pred.numpy())
        # print('squeeze pred: ', tf.squeeze(pred).numpy())

        for c in LETTER_LIST:
          # TODO: is there necessary to extend more symbols than beam_width?
          # extend the path
          new_path = path + c
          new_path_idx = path_idx + [letter2index[c]]
          # print('new path seq: ', new_path)
          # print('new path: ', new_path_idx)

          
          n_beam_idx[new_path] = new_path_idx
          n_pathscore[new_path] = pathscore[path] * tf.squeeze(pred).numpy()[letter2index[c]] # y[c]
          n_states[new_path] = next_states

          n_beam_seq.add(new_path)


      ## Beam Search
      ### TODO: pruning - done
      ### TODO: early termination, when one beam path ends in '<eos>'
      ### TODO: track the best path so far

      # beam_seq = n_beam_seq
      # beam_idx = n_beam_idx
      # pathscore = n_pathscore
      # states = n_states

      print("Pruning all candidate paths for step{}".format(step))

      beam_seq, beam_idx, pathscore, states = prune(n_beam_seq, n_beam_idx, n_pathscore, n_states)

     

    
    # list
    top_paths = sorted(pathscore.items(), key=lambda x: x[1], reverse=True)

    # print(utter.numpy())
    print("Input Target: ", target.numpy())
    print("Actual Transcript: ", og_trans[i])

    # list(word_freq.items())[0][1]
    print("Top Paths with Score: ", top_paths)

    for res in top_paths[:3]:
      print("Raw Prediction sequence {}, score: {}".format(res[0], res[1]))
      print("Raw Prediction idex: ", beam_idx[res[0]])
      # transform_index_to_letter accept multiple sentences
      print("Predicted Transcript: ", transform_index_to_letter([beam_idx[res[0]]], [letter2index['<eos>'], letter2index['<pad>']]))

    return beam_seq, beam_idx, pathscore

beam_seq, beam_idx, ps = val_beam(num_samples=1, max_seq=20)

## Debug/Sanity
print(len(beam_seq), beam_seq)

# from google.colab import drive
# drive.mount('/content/drive')

print(len(ps), ps)



"""###### Generate Test Result

"""

## Debug
for i, (utter, _, utter_len, _) in enumerate(batched_ds_test):
  print(utter.shape)
  print(utter_len)

### BEAM SEARCH
# For debug
np.set_printoptions(threshold=100)

max_seq = 250;
debug_mode = False


res = []

for i, (utter, _, utter_len, _) in enumerate(batched_ds_test):
  print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
  # Invoke Encoder
    # enc_output, enc_h, enc_c =  encoder(utter)
  # utter (1, len, F)
  # utter_len: (B, ) -> (1, ) in this case
  enc_output = inf_encoder(utter, utter_len)

  # enc_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
  # enc_c = tf.concat([enc_output[2], enc_output[4]], axis=1)

  # enc_reduced_len = enc_output[5]
  enc_reduced_len = enc_output[2] # separate key, value proj

  # Encoder output for current utterance, Hidden/High level representation H
  # Preparation
  path = '<sos>'
  beam_seq = set()
  beam_idx = {}
  pathscore = {}
  states = {}
  contexts = {} # Important, c-1/c_i-1
  best_path = path # dummy initial

  beam_seq.add(path)
  beam_idx[path] = [letter2index[path]]
  pathscore[path] = 1.0
  # states[path] =  [enc_h, enc_c]
  states[path] = None # initialize with zero-filled initial_states for all Decoder rnn layer(s)
  contexts[path] = None # initial context of 0's


  print('Initial Beam sequence: ', beam_seq)
  print('Initial Beam Idxs: ', beam_idx)

  terminated_seqs = {}

  for step in range(max_seq):

    if debug_mode:
      print("======================================Step : {} =============================================".format(step))
    n_beam_seq = set()
    n_beam_idx = {}
    n_pathscore = {}
    n_states = {}
    n_contexts = {}

    # 0. 'Tenure' the already terminated sequence(s)
    viable_beam_seq = set()

    for path in beam_seq:
      if beam_idx[path][-1] == letter2index['<eos>']:

        ## if current top scored path terminates with '<eos>', put it into candidates
        if path == best_path:
          print("Current Best Path: {} ended, put into candidates list...".format(best_path))
          # Early Stopping after find best path terminates in '<eos>' ...
          terminated_seqs[path] = pathscore[path]
          break
      else:
        viable_beam_seq.add(path)

    if len(terminated_seqs) > 0:
      break # early stop

    # 1. expore each path in beam
    for path in viable_beam_seq: #beam_seq:
      #print('step {}, path: {}'.format(step, path))
      path_idx = beam_idx[path]
      #print('sequence idx format: ', path_idx)

      cfin = tf.fill([1, 1], path_idx[-1])

      if debug_mode:
        print('step {}, path: {}'.format(step, path))
        print('sequence idx format: ', path_idx)
        print('dec input: ', cfin)

      if states[path] != None:
        hpath = states[path].copy() # !DON'T USE SHALLOW Copy -> $$$ avoid being altered in the decoder forward
      else:
        hpath = None

      if contexts[path] != None:
        path_context = tf.identity(contexts[path])
      else:
        path_context = None

      if debug_mode:
        print("-------------------States: ")
        for state_path in states.items():
          print("Path: {}, states: {}".format(state_path[0], state_path[1]))
      #   print("Input Label: ", cfin)
      #   print("Input Hidden States: ", hpath)
      #   print("Input Reduced Lens: ", enc_reduced_len)
      # TODO: this part can be Batched for all paths
      pred, next_states, _, next_contexts = inf_decoder(cfin, value=enc_output[0], key=enc_output[1], hidden=hpath, encoder_lens=enc_reduced_len, ini_context=path_context, debug_mode=False)
      if debug_mode:
        print("Next States Generated for {}: {}".format(cfin, next_states))
      # $$$ TODO plot the attention for beam search?


      ## Add Gumbel Noise... weird...
      dist = tfp.distributions.RelaxedOneHotCategorical(1, logits=pred)

      # (1, 1, Vocab_size)
      gumbel_pred = dist.sample()

      # print("Last Linear Layer :", pred.shape) # (1, 1, 35)
      # print('Pred :', pred.numpy())
      # $$$ Should use probablity value instead of raw Logits
      Y = tf.nn.softmax(tf.squeeze(pred))
      # Y = tf.nn.softmax(tf.squeeze(gumbel_pred)) # Add Gumbel Noise
      # if debug_mode:
      #   print('Raw Pred logits: ', pred)
      #   # print('Gumbel Noise added Pred Logits: ', gumbel_pred)
      #   # print('squeeze pred: ', tf.squeeze(pred).numpy())
      #   print('SoftMax pred: ', Y.numpy())

      for c in LETTER_LIST:
        # TODO: is there necessary to extend more symbols than beam_width?
        # extend the path
        new_path = path + c
        new_path_idx = path_idx + [letter2index[c]]
        # print('new path seq: ', new_path)
        # print('new path: ', new_path_idx)

        
        n_beam_idx[new_path] = new_path_idx
        # n_pathscore[new_path] = pathscore[path] * tf.squeeze(pred).numpy()[letter2index[c]] # y[c]
        n_pathscore[new_path] = pathscore[path] * Y.numpy()[letter2index[c]] # y[c]
        n_states[new_path] = next_states
        n_contexts[new_path] = next_contexts

        n_beam_seq.add(new_path)


    ## Beam Search
    ### TODO: pruning - done
    ### TODO: early termination, when one beam path ends in '<eos>'
    ### TODO: track the best path so far
    if debug_mode:
      print("Pruning all candidate paths for step {}".format(step))
    #   print("All next states: ")
    #   for state_path in n_states.items():
    #     print("Path: {}, states: {}".format(state_path[0], state_path[1]))

    beam_seq, beam_idx, pathscore, states, contexts, best_path = prune(n_beam_seq, n_beam_idx, n_pathscore, n_states, n_contexts, debug_mode=debug_mode, beam_width=10)

    if debug_mode:
      print("All Pruned next states: ")
      for state_path in states.items():
        print("Path: {}, states: {}".format(state_path[0], state_path[1]))

  
  # list
  top_paths = sorted(pathscore.items(), key=lambda x: x[1], reverse=True)
  top_terminated_paths = sorted(terminated_seqs.items(), key=lambda x: x[1], reverse=True)


  # list(word_freq.items())[0][1]
  print("Top Paths with Score: ", top_paths[:4])
  print("Top Terminated Paths with Score: ", top_terminated_paths)

  if len(top_terminated_paths) == 0:
    best_path_raw_str, best_path_score = top_paths[0]
  else:
    best_path_raw_str, best_path_score = top_terminated_paths[0]
  
  best_path_raw_idx = beam_idx[best_path_raw_str]

  print("Raw Prediction sequence {}, idices: {}".format(best_path_raw_str, best_path_raw_idx))
  print("Raw Prediction idex: ", best_path_raw_idx)
  # transform_index_to_letter accept multiple sentences
  spell = transform_index_to_letter([best_path_raw_idx], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])
  print("Predicted Transcript: ", spell)

  res.append(spell)

### Greedy Search
max_seq = 250
res = []
debug_mode = False

for i, (utter, _, utter_len, _) in enumerate(batched_ds_test):
  print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
  # Invoke Encoder

  enc_output = inf_encoder(utter, utter_len)

  enc_reduced_len = enc_output[2] # separate key and value proj

  # enc_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
  # enc_c = tf.concat([enc_output[2], enc_output[4]], axis=1)


  dec_input = tf.fill([1, 1], letter2index['<sos>']) # start of sequence # (1, 1)
  
  seq = ['<sos>']
  seq_index = [letter2index['<sos>']]
  # initial Decoder State
  # Use Encoder hidden states for now, s-1=hN
  ## Use zero-filled initial states
  # h_state = enc_h
  # c_state = enc_c
  states = None

  # Initial Context, c-1, c0
  context = None

  attention = []

  # ## TEMP Solution
  # dec_input = tf.fill([1, max_seq], letter2index['<sos>']) # start of sequence # (1, 1)

  # pred, dec_next_states, attention_sample = inf_decoder(dec_input, value=enc_output[0], hidden=None, encoder_lens=enc_reduced_len, teacher_force=True, teacher_forcing_rate=1.0) # take sample from previous ts output distributions all the time

  # # Greedy Decode
  # pred_trans = tf.math.argmax(pred, axis=-1)

  # pred_text = transform_index_to_letter(pred_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

  while tf.squeeze(dec_input).numpy() != letter2index['<eos>'] and len(seq) < max_seq:

    if debug_mode:
        print("Input Label: ", dec_input)
        print("Input Hidden States: ", states)
        print("Input Reduced Lens: ", enc_reduced_len)
    # the input context is always zero... if we 'run_one_step'
    pred, next_states, att_step, context = inf_decoder(dec_input, value=enc_output[0], key=enc_output[1], hidden=states, encoder_lens=enc_reduced_len, ini_context=context, debug_mode=False)

    # (1, Utter_len)
    attention.append(att_step)

    states = next_states

    # pred: (1, 1, 35/vocab_size)
    if debug_mode:
      print("step: {}".format(len(seq)))
      print("current seq: ", seq)
      print("pred: ", pred.numpy())
      print("SoftMax pred: ", tf.nn.softmax(tf.squeeze(pred)).numpy())


    # $$ Greedy Search
    next_input =  tf.math.argmax(tf.squeeze(pred), axis=-1)
    if debug_mode:
      print("Input for next step: {}, Letter: {}".format(next_input.numpy(), index2letter[next_input.numpy()]))
    dec_input = tf.fill([1,1], next_input)
    seq.append(index2letter[next_input.numpy()])
    seq_index.append(next_input.numpy())

  decoded = transform_index_to_letter([seq_index], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])
  print("Raw Prediction sequence :", seq)
  print("Raw Prediction sequence(indices) :", seq_index)
  print("Predicted Transcript: ", decoded)
  att_sample = tf.concat(attention, axis=0)
  print("Attention: ", att_sample.shape)
  plt.matshow(att_sample)
  plt.show()


  res.append(decoded)

### Greedy Search with Gumbel
np.set_printoptions(threshold=100)

max_seq = 100 # 250
res = []
debug_mode = False

for i, (utter, _, utter_len, _) in enumerate(batched_ds_test.take(1)):
  print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
  # Invoke Encoder

  enc_output = inf_encoder(utter, utter_len)

  enc_reduced_len = enc_output[2]

  # enc_h = tf.concat([enc_output[1], enc_output[3]], axis=1)
  # enc_c = tf.concat([enc_output[2], enc_output[4]], axis=1)


    

  # dec_input = tf.fill([1, 1], letter2index['<sos>']) # start of sequence # (1, 1)
  
  seq = ['<sos>']
  seq_index = [letter2index['<sos>']]
  # initial Decoder State
  # Use Encoder hidden states for now, s-1=hN
  ## Use zero-filled initial states
  # h_state = enc_h
  # c_state = enc_c
  states = None

  ## TEMP Solution
  dec_input = tf.fill([1, max_seq], letter2index['<sos>']) # start of sequence # (1, 1)

  pred, dec_next_states, attention_sample = inf_decoder(dec_input, value=enc_output[0], key=enc_output[1], hidden=None, encoder_lens=enc_reduced_len, teacher_force=True, teacher_forcing_rate=1.0, debug_mode=True) # take sample from previous ts output distributions all the time

  # Greedy Decode
  pred_trans = tf.math.argmax(pred, axis=-1)

  pred_text = transform_index_to_letter(pred_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

  # while tf.squeeze(dec_input).numpy() != letter2index['<eos>'] and len(seq) < max_seq:

  #   pred, next_states, _ = inf_decoder(dec_input, value=enc_output[0], hidden=states, encoder_lens=enc_reduced_len)

  #   # h_state = next_states[0]
  #   # c_state = next_states[1]
  #   states = next_states

  #   # pred: (1, 1, 35/vocab_size)
  #   if debug_mode:
  #     print("step: {}".format(len(seq)))
  #     print("current seq: ", seq)
  #     print("pred: ", pred.numpy())
  #     print("SoftMax pred: ", tf.nn.softmax(tf.squeeze(pred)).numpy())


  #   # $$ Greedy Search
  #   next_input =  tf.math.argmax(tf.squeeze(pred), axis=-1)
  #   dec_input = tf.fill([1,1], next_input)
  #   seq.append(index2letter[next_input.numpy()])
  #   seq_index.append(next_input.numpy())

  # decoded = transform_index_to_letter([seq_index], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])
  # print("Raw Prediction sequence :", seq)
  # print("Predicted Transcript: ", decoded)

  # res.append(decoded)
  print("Raw Prediction sequence(indices) :", pred_trans)
  print("Predicted Transcript: ", pred_text)
  print(pred_text[0])

  # Plot attention
  plt.matshow(attention_sample)
  plt.show()

  res.append(pred_text[0])

## Greedy Search Debug


max_seq = 250 # 250
res = []
debug_mode = False

for i, (utter, _, utter_len, _) in enumerate(batched_ds_test.take(1)):
  print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
  # Invoke Encoder

  enc_output = inf_encoder(utter, utter_len)

  enc_reduced_len = enc_output[2]

  
  seq = ['<sos>']
  seq_index = [letter2index['<sos>']]
  # initial Decoder State
  ## Use zero-filled initial states

  states = None

  ## TEMP Solution
  dec_input = tf.fill([1, max_seq], letter2index['<sos>']) # start of sequence # (1, 1)

  pred, dec_next_states, attention_sample, _ = inf_decoder(dec_input, value=enc_output[0], key=enc_output[1], hidden=None, encoder_lens=enc_reduced_len, teacher_force=False, if_generate=True, debug_mode=True) # take the max prob char from previous ts distribution

  # Greedy Decode
  pred_trans = tf.math.argmax(pred, axis=-1)

  pred_text = transform_index_to_letter(pred_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

  # while tf.squeeze(dec_input).numpy() != letter2index['<eos>'] and len(seq) < max_seq:

  #   pred, next_states, _ = inf_decoder(dec_input, value=enc_output[0], hidden=states, encoder_lens=enc_reduced_len)

  #   # h_state = next_states[0]
  #   # c_state = next_states[1]
  #   states = next_states

  #   # pred: (1, 1, 35/vocab_size)
  #   if debug_mode:
  #     print("step: {}".format(len(seq)))
  #     print("current seq: ", seq)
  #     print("pred: ", pred.numpy())
  #     print("SoftMax pred: ", tf.nn.softmax(tf.squeeze(pred)).numpy())


  #   # $$ Greedy Search
  #   next_input =  tf.math.argmax(tf.squeeze(pred), axis=-1)
  #   dec_input = tf.fill([1,1], next_input)
  #   seq.append(index2letter[next_input.numpy()])
  #   seq_index.append(next_input.numpy())

  # decoded = transform_index_to_letter([seq_index], [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])
  # print("Raw Prediction sequence :", seq)
  # print("Predicted Transcript: ", decoded)

  # res.append(decoded)
  print("Raw Prediction sequence(indices) :", pred_trans)
  print("Predicted Transcript: ", pred_text)
  print(pred_text[0])
  print(attention_sample.shape)

  # Plot attention
  plt.matshow(attention_sample)
  plt.show()

"""#### Random Search"""

### Random Search
max_seq = 250
random_search = 10
res = []
debug_mode = False

for i, (utter, _, utter_len, _) in enumerate(batched_ds_test):
  print("===================================Raw Utterance {}: ===================================\n {}".format(i, utter.numpy()))
  # Invoke Encoder

  enc_output = inf_encoder(utter, utter_len)

  enc_reduced_len = enc_output[1]

  print("Og uttern len: {}, Reduced by pBLSTM len: {}".format(utter_len, enc_reduced_len))

  best_loss = 1e10
  best_seq = None
  best_att = None

  for i in range(random_search):


    ## TEMP Solution
    ### (1, T_max)
    dec_input = tf.fill([1, max_seq], letter2index['<sos>']) # start of sequence # (1, 1)
    # print(dec_input)

    pred, dec_next_states, _ = inf_decoder(dec_input, value=enc_output[0], hidden=None, encoder_lens=enc_reduced_len, teacher_force=True, teacher_forcing_rate=1.0) # take sample from previous ts output distributions all the time

    # pred: (1, T_max, vocab_size)
    # Greedy Decode
    # the target (1, T_max)
    pred_trans = tf.math.argmax(pred, axis=-1)

    ## feeding the predicted sequences back through the network as targets
    # (1, T_max)
    trans_input = tf.concat([tf.cast(tf.fill([1, 1],letter2index['<sos>']), tf.int64), pred_trans[:, :-1]], axis=1) # remove last char, add <sos> up front
    # print("Re-feed input shape: ", trans_input.shape)
    # print("Refeed input: ", trans_input)
    # print("Target Seq: ", pred_trans)

    raw_logits, _, attention_sample = inf_decoder(trans_input, value=enc_output[0], hidden=None, encoder_lens=enc_reduced_len, teacher_force=False) # # Simply do the feed

    ## Compute the loss
    loss, unmasked_loss = loss_function(pred_trans, raw_logits, tf.fill([1, max_seq], 1.0))

    # print("Current Sample loss: {}, unmasked_loss {}".format(loss, unmasked_loss))

    if loss < best_loss:
      best_loss = loss
      best_seq = pred_trans
      # (T_max, U_current)
      best_att = attention_sample
      # print(best_att.shape)

  #   pred_text = transform_index_to_letter(pred_trans.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

  #   loss, unmasked_loss = loss_function(target, pred, target_mask)

  pred_text = transform_index_to_letter(best_seq.numpy(), [letter2index['<eos>'], letter2index['<pad>']], igonre_idxs=[letter2index['<sos>']])

  print("Raw Prediction sequence(indices) :", best_seq)
  print("Predicted Transcript: ", pred_text)
  print(pred_text[0])

  plt.matshow(best_att)
  plt.show()

  res.append(pred_text[0])

## Write decoded/prediced results to CSV
df = pd.DataFrame(res, columns=['Predicted'])
df.index.name = 'id'
df.to_csv('./colab_storage/LAS/submission.csv')

